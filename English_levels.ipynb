{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Подгружаем библеотеку для чтения субтитров\n",
    "import pysrt\n",
    "# Подгружаем библеотеку для получения списка специальных символов\n",
    "import string\n",
    "# Подгружаем библеотеки для выделения слов из текста\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "# Подгружаем библиотеку для преобразования слов в их исходное значение (к корню)\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Подгружаем библиотеки для получения списка файлов из папки\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import nltk\n",
    "print(nltk.__version__)\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функции используемые в проекте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "# Функция для загрузки данных, хранящих информацию об уровнях английского\n",
    "def func_load(file):\n",
    "    \n",
    "    # загрузим данные\n",
    "    try:\n",
    "        data_levels = pd.read_excel(file)\n",
    "        \n",
    "    except:\n",
    "        print('Проблема с данными, попробуйте снова.')\n",
    "    \n",
    "    return data_levels\n",
    "\n",
    "# 2\n",
    "# Функция для формирования общего массива слов из фремов с уровнями английского\n",
    "def united_words(*args):\n",
    "    \n",
    "    united = []\n",
    "    \n",
    "    # запустим обработку фреймов с учетом, того что их может быть много\n",
    "    for arg in args:        \n",
    "        for column in arg.columns:\n",
    "            # пройдемся циклом по всем элементам из столбцов до появления пропусков\n",
    "            for word in (np.array(arg[arg[column].isna() == False][column])):\n",
    "                united.append(word)\n",
    "\n",
    "    return united\n",
    "\n",
    "# 3\n",
    "# Функция для удаления лишних символов\n",
    "def remove_symbol(text, symbols_to_delete):\n",
    "    for symbol in symbols_to_delete:\n",
    "        text = text.replace(str(symbol), '')\n",
    "    return text\n",
    "\n",
    "# 4\n",
    "# Функция для разделения текста по словам с удалением стоп-слов\n",
    "def transform_text(text):\n",
    "    \n",
    "    # разделяем текст по словам (токенам)\n",
    "    word_tokens = word_tokenize(text)\n",
    "    # приводим слова к изначальной форме\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = [lemmatizer.lemmatize(word, pos ='v') for word in word_tokens]\n",
    "    \n",
    "    return lemmas\n",
    "\n",
    "# 5\n",
    "# Функция для чтения субтитров и преобразования их в удобный для обработки вид\n",
    "def subs_transform(file):\n",
    "    \n",
    "    # чтение субтитров из файла\n",
    "    subs = pysrt.open(file, encoding='iso-8859-1')\n",
    "\n",
    "    # объединим субтитры в один единый текст\n",
    "    subs_union = \"\".join([str(sub) for sub in subs])\n",
    "\n",
    "    # уберём все лишние символы, такие как цифры и специальные символы вместе со знаком перевода строки\n",
    "    subs_union = remove_symbol(subs_union, DIGITS + PUNCTUATIONS)\n",
    "\n",
    "    # переведём всё в нижний регистр\n",
    "    subs_union = subs_union.lower()\n",
    "    \n",
    "    # преобразуем текст субтитров в список слов\n",
    "    subs_union = transform_text(subs_union)\n",
    "    \n",
    "    return subs_union\n",
    "\n",
    "# 6\n",
    "# Функция для масштабирования частоты появления слов\n",
    "def freq_word_scal(subs, freq_word_subs):\n",
    "        '''\n",
    "        Данная функция необходима, для того избавится от проблемы больших и маленьких текстов.\n",
    "        Имеется ввиду следующее, если фильм длинной около 3 часов, то количество слов в субтитрах \n",
    "        будет существенно больше чем в фильме длинной час. Для этого, будем находить долю частоты\n",
    "        появления конкретного слова от общего числа слов в тексте. \n",
    "        '''\n",
    "        # найдём общее количество слов в субтитрах\n",
    "        count_words = len(subs)\n",
    "        \n",
    "        # запустим цикл по словарю частот слов, получая доли от общего числа слов в субтитрах\n",
    "        for key in freq_word_subs.keys():\n",
    "            try:\n",
    "                freq_word_subs[key] = freq_word_subs[key] / count_words\n",
    "            except:\n",
    "                freq_word_subs[key] = 0\n",
    "            \n",
    "        return freq_word_subs\n",
    "    \n",
    "# 7\n",
    "# Функция для подсчета частоты повторения слов\n",
    "def frequency_word(list_word_from_text, list_word_by_levels):\n",
    "    \n",
    "    # объявим словарь, который будет собирать частоты появления слов\n",
    "    freq_words = {}\n",
    "    \n",
    "    # запускаем цикл по словам из списка уникальных значений, на основе которых, \n",
    "    # выстраиваются уровни владения языком (уровневый список)\n",
    "    for level_word in list_word_by_levels:\n",
    "        # для удобства, вначале будем присваивать ноль для базового значения частот слов\n",
    "        freq_words[level_word] = 0\n",
    "        # запускаем цикл по словам из списка текста\n",
    "        for text_word in list_word_from_text:\n",
    "            # подсчёт частот производится на основе равенства слов из уровнего списка со словами из текста\n",
    "            if(level_word == text_word):\n",
    "                freq_words[level_word] += 1\n",
    "                \n",
    "    # произведём масштабирование частот слов\n",
    "    freq_words = freq_word_scal(list_word_from_text, freq_words)\n",
    "                \n",
    "    return freq_words\n",
    "\n",
    "# 8\n",
    "# Функция для получения списка файлов в заданной папке\n",
    "def func_list_files(folder_path):\n",
    "    \n",
    "    # получим список файлов\n",
    "    list_files = [folder_path + f for f in listdir(folder_path) if isfile(join(folder_path, f))]\n",
    "    \n",
    "    return list_files\n",
    "\n",
    "# 9 \n",
    "# Функция, осуществляющая разметку текстов из заданной папки, c получением общего фрейма данных\n",
    "def text_markup(folder_path, combined_unique_words):\n",
    "    \n",
    "    # получим список файлов для разметки\n",
    "    list_files = func_list_files(folder_path)\n",
    "    \n",
    "    # объявим матрицу частот слов, переменную для хранения субтитров,\n",
    "    # массив, содержащий текущий набор частот слов и результирующий фрейм данных\n",
    "    matrix_values = [] \n",
    "    subs = ''\n",
    "    freq_words = []\n",
    "    result = pd.DataFrame()\n",
    "    \n",
    "    # запустим обработку всех текстовых файлов в заданном каталоге\n",
    "    for file in list_files:\n",
    "        \n",
    "        # обработка текущего файла субтитров\n",
    "        subs = subs_transform(file)\n",
    "        # получим массив значений частот слов\n",
    "        freq_words = [val for val in frequency_word(subs, combined_unique_words).values()]\n",
    "        \n",
    "        # добавим получившуюся вектор-строку в матрицу значений\n",
    "        matrix_values.append(freq_words)\n",
    "        \n",
    "    # сформируем обобщённый фрейм данных, который будет содержать частоты слов для каждого фильма \n",
    "    result = pd.DataFrame(data=matrix_values, columns=combined_unique_words)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# перечень используемых в проекте констант\n",
    "\n",
    "# Цифры\n",
    "DIGITS = ''.join([str(digit) for digit in range(10)])\n",
    "\n",
    "# Знаки препинания и символ перевода строки\n",
    "PUNCTUATIONS = string.punctuation + '\\n'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1_lite</th>\n",
       "      <th>A2_lite</th>\n",
       "      <th>B1_lite</th>\n",
       "      <th>B2_lite</th>\n",
       "      <th>B2_hard</th>\n",
       "      <th>C1_hard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>ability</td>\n",
       "      <td>academic</td>\n",
       "      <td>abandon</td>\n",
       "      <td>absorb</td>\n",
       "      <td>acceptance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>an</td>\n",
       "      <td>able</td>\n",
       "      <td>access</td>\n",
       "      <td>absolute</td>\n",
       "      <td>abstract</td>\n",
       "      <td>accessible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>about</td>\n",
       "      <td>abroad</td>\n",
       "      <td>accommodation</td>\n",
       "      <td>academic</td>\n",
       "      <td>accent</td>\n",
       "      <td>accomplishment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>above</td>\n",
       "      <td>accept</td>\n",
       "      <td>account</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>accidentally</td>\n",
       "      <td>accordance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>across</td>\n",
       "      <td>accident</td>\n",
       "      <td>achievement</td>\n",
       "      <td>accompany</td>\n",
       "      <td>accommodate</td>\n",
       "      <td>accordingly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  A1_lite   A2_lite        B1_lite     B2_lite       B2_hard         C1_hard\n",
       "0       a   ability       academic     abandon        absorb      acceptance\n",
       "1      an      able         access    absolute      abstract      accessible\n",
       "2   about    abroad  accommodation    academic        accent  accomplishment\n",
       "3   above    accept        account  acceptable  accidentally      accordance\n",
       "4  across  accident    achievement   accompany   accommodate     accordingly"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1_lite</th>\n",
       "      <th>A2_lite</th>\n",
       "      <th>B1_lite</th>\n",
       "      <th>B2_lite</th>\n",
       "      <th>B2_hard</th>\n",
       "      <th>C1_hard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>action</td>\n",
       "      <td>ability</td>\n",
       "      <td>absolutely</td>\n",
       "      <td>abandon</td>\n",
       "      <td>absorb</td>\n",
       "      <td>abolish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>activity</td>\n",
       "      <td>able</td>\n",
       "      <td>academic</td>\n",
       "      <td>abroad</td>\n",
       "      <td>abstract</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>actor</td>\n",
       "      <td>accept</td>\n",
       "      <td>access</td>\n",
       "      <td>absolute</td>\n",
       "      <td>accent</td>\n",
       "      <td>absence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>actress</td>\n",
       "      <td>accident</td>\n",
       "      <td>account</td>\n",
       "      <td>acceptable</td>\n",
       "      <td>accidentally</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>add</td>\n",
       "      <td>according to</td>\n",
       "      <td>achievement</td>\n",
       "      <td>accompany</td>\n",
       "      <td>accommodate</td>\n",
       "      <td>absurd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A1_lite       A2_lite      B1_lite     B2_lite       B2_hard   C1_hard\n",
       "0    action       ability   absolutely     abandon        absorb   abolish\n",
       "1  activity          able     academic      abroad      abstract  abortion\n",
       "2     actor        accept       access    absolute        accent   absence\n",
       "3   actress      accident      account  acceptable  accidentally    absent\n",
       "4       add  according to  achievement   accompany   accommodate    absurd"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10_Cloverfield_lane(2016)</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10_things_I_hate_about_you(1999)</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A_knights_tale(2001)</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A_star_is_born(2018)</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Aladdin(1992)</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>223</td>\n",
       "      <td>Matilda(2022)</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>224</td>\n",
       "      <td>Bullet train</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>225</td>\n",
       "      <td>Thor: love and thunder</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>226</td>\n",
       "      <td>Lightyear</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>227</td>\n",
       "      <td>The Grinch</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                             Movie Level\n",
       "0      0         10_Cloverfield_lane(2016)    B1\n",
       "1      1  10_things_I_hate_about_you(1999)    B1\n",
       "2      2              A_knights_tale(2001)    B2\n",
       "3      3              A_star_is_born(2018)    B2\n",
       "4      4                     Aladdin(1992)    A2\n",
       "..   ...                               ...   ...\n",
       "223  223                     Matilda(2022)    C1\n",
       "224  224                      Bullet train    B1\n",
       "225  225            Thor: love and thunder    B2\n",
       "226  226                         Lightyear    B2\n",
       "227  227                        The Grinch    B1\n",
       "\n",
       "[228 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# загрузим данные по уровням для английского языка \n",
    "english_levels = func_load('British_levels.xlsx')\n",
    "display(english_levels.head(5))\n",
    "\n",
    "# загрузим данные по уровням для американского языка \n",
    "americ_levels = func_load('American_levels.xlsx')\n",
    "display(americ_levels.head(5))\n",
    "\n",
    "# загрузим файл, в котором хранится информация о сложности фильмов\n",
    "movies_levels = func_load('movies_labels.xlsx')\n",
    "display(movies_levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формирование фрейма данных с частотами слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Соберём единый массив, который будет содержать все уникальные слова\n",
    "united = pd.Series(united_words(english_levels, americ_levels)).unique()\n",
    "\n",
    "# получим список файлов для разметки\n",
    "list_files = func_list_files('Subtitles/')\n",
    "# удалим расширение файлов \".srt\"\n",
    "list_files = [remove_symbol(file,['Subtitles/', '.srt']) for file in list_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>an</th>\n",
       "      <th>about</th>\n",
       "      <th>above</th>\n",
       "      <th>across</th>\n",
       "      <th>action</th>\n",
       "      <th>activity</th>\n",
       "      <th>actor</th>\n",
       "      <th>actress</th>\n",
       "      <th>add</th>\n",
       "      <th>...</th>\n",
       "      <th>rumor</th>\n",
       "      <th>setup</th>\n",
       "      <th>skeptical</th>\n",
       "      <th>sophomore</th>\n",
       "      <th>superintendent</th>\n",
       "      <th>tumor</th>\n",
       "      <th>unconstitutional</th>\n",
       "      <th>Movie</th>\n",
       "      <th>id</th>\n",
       "      <th>Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.017082</td>\n",
       "      <td>0.002749</td>\n",
       "      <td>0.003534</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10_Cloverfield_lane(2016)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021591</td>\n",
       "      <td>0.001570</td>\n",
       "      <td>0.003664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10_things_I_hate_about_you(1999)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021688</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.001363</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Aladdin(1992)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.017564</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.001584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>All_dogs_go_to_heaven(1989)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.021161</td>\n",
       "      <td>0.001719</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AmericanBeauty1999.BRRip</td>\n",
       "      <td>105.0</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          a        an     about     above    across    action  activity  \\\n",
       "0  0.017082  0.002749  0.003534  0.000982  0.000196  0.000000       0.0   \n",
       "1  0.021591  0.001570  0.003664  0.000000  0.000000  0.000131       0.0   \n",
       "2  0.021688  0.000744  0.001363  0.000000  0.000000  0.000124       0.0   \n",
       "3  0.017564  0.001008  0.001584  0.000000  0.000000  0.000144       0.0   \n",
       "4  0.021161  0.001719  0.004100  0.000132  0.000000  0.000000       0.0   \n",
       "\n",
       "   actor  actress       add  ...     rumor     setup  skeptical  sophomore  \\\n",
       "0    0.0      0.0  0.000000  ...  0.000000  0.000000        0.0   0.000000   \n",
       "1    0.0      0.0  0.000000  ...  0.000262  0.000131        0.0   0.000262   \n",
       "2    0.0      0.0  0.000000  ...  0.000000  0.000000        0.0   0.000000   \n",
       "3    0.0      0.0  0.000000  ...  0.000000  0.000000        0.0   0.000000   \n",
       "4    0.0      0.0  0.000132  ...  0.000000  0.000000        0.0   0.000000   \n",
       "\n",
       "   superintendent  tumor  unconstitutional                             Movie  \\\n",
       "0             0.0    0.0               0.0         10_Cloverfield_lane(2016)   \n",
       "1             0.0    0.0               0.0  10_things_I_hate_about_you(1999)   \n",
       "2             0.0    0.0               0.0                     Aladdin(1992)   \n",
       "3             0.0    0.0               0.0       All_dogs_go_to_heaven(1989)   \n",
       "4             0.0    0.0               0.0          AmericanBeauty1999.BRRip   \n",
       "\n",
       "      id  Level  \n",
       "0    0.0     B1  \n",
       "1    1.0     B1  \n",
       "2    4.0     A2  \n",
       "3    5.0     A2  \n",
       "4  105.0     B1  \n",
       "\n",
       "[5 rows x 5107 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# сформируем фрейм данных с частотами повторений слов\n",
    "data = text_markup('Subtitles/', united)\n",
    "# добавим в фрейм поле с названиями фильмов\n",
    "data['Movie'] = list_files\n",
    "\n",
    "# объединим фреймы \"сложность фильмов\" и \"частоты повторений слов\"\n",
    "data = data.merge(movies_levels, how='left', on='Movie')\n",
    "\n",
    "display(data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "379.387px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
